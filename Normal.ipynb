{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeGqogIZS3EQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(1, input_dim=X_train.shape[1], activation='linear')\n",
        "])\n",
        "model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
        "\n",
        "y_pred = model.predict(X_test).flatten()\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "X = 6 * np.random.rand(200, 1) - 3\n",
        "y = 0.8 * X**2 + 0.9 * X + 2 + np.random.randn(200, 1)\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, include_bias=True)\n",
        "x_train_trans = poly.fit_transform(x_train)\n",
        "x_test_trans = poly.transform(x_test)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(x_train_trans.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "history = model.fit(x_train_trans, y_train, epochs=200, batch_size=10, validation_data=(x_test_trans, y_test), verbose=0)\n",
        "\n",
        "y_pred = model.predict(x_test_trans)\n",
        "print(f\"R2 score on test data: {r2_score(y_test, y_pred)}\")\n",
        "\n",
        "X_new = np.linspace(-3, 3, 200).reshape(200, 1)\n",
        "X_new_poly = poly.transform(X_new)\n",
        "y_new = model.predict(X_new_poly)\n",
        "\n",
        "plt.plot(X_new, y_new, \"r-\", linewidth=2, label=\"Predictions\")\n",
        "plt.plot(x_train, y_train, \"b.\", label=\"Training points\")\n",
        "plt.plot(x_test, y_test, \"g.\", label=\"Testing points\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "u0ZK7QN0T8im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X, y = make_blobs(n_samples=200, centers=2, random_state=42)\n",
        "X = StandardScaler().fit_transform(X)\n",
        "model = Sequential([Dense(1, input_dim=2, activation='sigmoid')])\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy')\n",
        "model.fit(X, y, epochs=10, verbose=0)\n",
        "xx, yy = np.meshgrid(np.linspace(-3, 3, 100), np.linspace(-3, 3, 100))\n",
        "grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "probs = model.predict(grid).reshape(xx.shape)\n",
        "plt.contourf(xx, yy, probs, levels=[0, 0.5, 1], alpha=0.2, colors=['blue', 'orange'])\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9B2KfvQZUajR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "model = Sequential([\n",
        " Flatten(input_shape=(28, 28)),\n",
        " Dense(128, activation='relu'),\n",
        " Dense(64, activation='relu'),\n",
        " Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "CbAMYvXFWAEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "model = Sequential([\n",
        " Flatten(input_shape=(28, 28)),\n",
        " Dense(64, activation='relu'),\n",
        " Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "A8OyANWBWPCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model = Sequential([\n",
        " Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
        " Dense(64, activation='relu'),\n",
        " Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
        "loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Mean Squared Error: {loss:.4f}\")"
      ],
      "metadata": {
        "id": "jd2zgGP4Wk7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Flatten, Dense, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = np.expand_dims(X_train, axis=-1).astype('float32') / 255\n",
        "X_test = np.expand_dims(X_test, axis=-1).astype('float32') / 255\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "model = Sequential([\n",
        " Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        " BatchNormalization(),\n",
        " MaxPooling2D(pool_size=(2, 2)),\n",
        " Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        " BatchNormalization(),\n",
        " MaxPooling2D(pool_size=(2, 2)),\n",
        " Flatten(),\n",
        " Dense(128, activation='relu'),\n",
        " Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=1, batch_size=32, verbose=1)\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "tfeHOf8cWwpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Input\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "input_img = Input(shape=(128, 128, 3))\n",
        "x = Conv2D(32, (3, 3), activation='relu')(input_img)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "\n",
        "model = Model(inputs=input_img, outputs=x)\n",
        "img = image.load_img('dawg.jpg', target_size=(128, 128))\n",
        "img_tensor = np.expand_dims(image.img_to_array(img) / 255.0, axis=0)\n",
        "layer_outputs = [layer.output for layer in model.layers if 'conv' in layer.name]\n",
        "\n",
        "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
        "activations = activation_model.predict(img_tensor)\n",
        "\n",
        "for layer_activation in activations:\n",
        "    n_features = layer_activation.shape[-1]\n",
        "    n_cols = 8\n",
        "    fig, axes = plt.subplots(n_features // n_cols, n_cols, figsize=(12, 12))\n",
        "    for i in range(n_features):\n",
        "        ax = axes[i // n_cols, i % n_cols]\n",
        "        ax.imshow(layer_activation[0, :, :, i], cmap='viridis')\n",
        "        ax.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "S7C41impapky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "X_val, y_val = X_train[-10000:], y_train[-10000:]\n",
        "X_train, y_train = X_train[:-10000], y_train[:-10000]\n",
        "model = Sequential([\n",
        " Flatten(input_shape=(28, 28)),\n",
        " Dense(128, activation='relu'),\n",
        " Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
        " epochs=5, batch_size=32, callbacks=[early_stopping], verbose=1)\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "rKqZziSpcc_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D,Dense,Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299) + (3,))\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = GlobalAveragePooling2D()(model.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x =Dropout(0.5)(x)\n",
        "output = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=model.input, outputs=output)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "train_data, test_data = tfds.load('cifar10', split=['train', 'test'], as_supervised=True)\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (299, 299))\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = preprocess_input(image)\n",
        "    label = tf.one_hot(label, 10)\n",
        "    return image, label\n",
        "\n",
        "train_data = train_data.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_data = test_data.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "history = model.fit(train_data, epochs=1, validation_data=test_data)\n",
        "loss, accuracy = model.evaluate(test_data, verbose=0); print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "N2gKCuFzdJzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(10, activation='softmax')(x)\n",
        "model = keras.models.Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_data, test_data = tfds.load('cifar10', split=['train', 'test'], as_supervised=True)\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
        "    label = tf.one_hot(label, 10)\n",
        "    return image, label\n",
        "train_data = train_data.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_data = test_data.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "history = model.fit(train_data, epochs=1, validation_data=test_data)\n",
        "loss, accuracy = model.evaluate(test_data, verbose=0)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "R8mg9qFceqCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 1\n",
        "\n",
        "(train_data, test_data), dataset_info = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "train_data = train_data.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_data = test_data.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_data\n",
        ")\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "selgvixrfU64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 1\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "(train_data, test_data), dataset_info = tfds.load(\n",
        "    'cifar10',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "train_data = train_data.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_data = test_data.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_data\n",
        ")\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "aKdWQoZ7iQ4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 1\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "(train_data, test_data), dataset_info = tfds.load(\n",
        "    'cifar10',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "train_data = train_data.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_data = test_data.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_data\n",
        ")\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "p2_NNg62ktUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow_datasets as tfds\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 1\n",
        "NUM_CLASSES = 5\n",
        "(train_data, test_data), dataset_info = tfds.load(\n",
        "    'tf_flowers',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
        "    return image, label\n",
        "train_data = train_data.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_data = test_data.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_data\n",
        ")\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "VN-uJBejlh7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow_datasets as tfds\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "NUM_CLASSES = 10\n",
        "(train_data, test_data), dataset_info = tfds.load(\n",
        "    'cifar10',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.keras.applications.densenet.preprocess_input(image)\n",
        "    return image, label\n",
        "train_data = train_data.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_data = test_data.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_data\n",
        ")\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "FMN3JR4ml7Vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "x_train = pad_sequences(x_train, maxlen=200)\n",
        "x_test = pad_sequences(x_test, maxlen=200)\n",
        "model = Sequential([\n",
        " Embedding(input_dim=10000, output_dim=128, input_length=200),\n",
        " SimpleRNN(128),\n",
        " Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=1, batch_size=64, validation_split=0.2)\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "nmXP2zeCmF9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import f1_score\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "x_train = pad_sequences(x_train, maxlen=200)\n",
        "x_test = pad_sequences(x_test, maxlen=200)\n",
        "model = Sequential([\n",
        " Embedding(input_dim=10000, output_dim=128, input_length=200),\n",
        " LSTM(128),\n",
        " Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=1, batch_size=64, validation_split=0.2)\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "accuracy = np.mean(y_pred.flatten() == y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "HMMX1ux2mRNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=200)\n",
        "x_test = pad_sequences(x_test, maxlen=200)\n",
        "\n",
        "def train_model(model):\n",
        " model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        " model.fit(x_train, y_train, epochs=1, batch_size=64, validation_split=0.2)\n",
        " return model\n",
        "\n",
        "lstm_model = Sequential([\n",
        " Embedding(input_dim=10000, output_dim=128, input_length=200),\n",
        " LSTM(128),\n",
        " Dense(1, activation='sigmoid')\n",
        "])\n",
        "lstm_model = train_model(lstm_model)\n",
        "\n",
        "y_pred_lstm = (lstm_model.predict(x_test) > 0.5).astype(int)\n",
        "accuracy_lstm = np.mean(y_pred_lstm.flatten() == y_test)\n",
        "f1_lstm = f1_score(y_test, y_pred_lstm)\n",
        "\n",
        "gru_model = Sequential([\n",
        " Embedding(input_dim=10000, output_dim=128, input_length=200),\n",
        " GRU(128),\n",
        " Dense(1, activation='sigmoid')\n",
        "])\n",
        "gru_model = train_model(gru_model)\n",
        "\n",
        "y_pred_gru = (gru_model.predict(x_test) > 0.5).astype(int)\n",
        "accuracy_gru = np.mean(y_pred_gru.flatten() == y_test)\n",
        "f1_gru = f1_score(y_test, y_pred_gru)\n",
        "\n",
        "print(f\"LSTM Test accuracy: {accuracy_lstm:.4f}, F1 score: {f1_lstm:.4f}\")\n",
        "print(f\"GRU Test accuracy: {accuracy_gru:.4f}, F1 score: {f1_gru:.4f}\")\n"
      ],
      "metadata": {
        "id": "Nrrp10MvmiFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=200)\n",
        "x_test = pad_sequences(x_test, maxlen=200)\n",
        "\n",
        "model = Sequential([\n",
        " Embedding(input_dim=10000, output_dim=128, input_length=200),\n",
        " LSTM(128),\n",
        " Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=1, batch_size=64, validation_split=0.2)\n",
        "\n",
        "y_pred = (model.predict(x_test) > 0.5).astype(int)\n",
        "accuracy = np.mean(y_pred.flatten() == y_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Test accuracy: {accuracy:.4f}, F1 score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "N01vGntWmss0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "x_train = pad_sequences(x_train, maxlen=200)\n",
        "x_test = pad_sequences(x_test, maxlen=200)\n",
        "model = Sequential([\n",
        " Embedding(input_dim=10000, output_dim=128, input_length=200),\n",
        " LSTM(128),\n",
        " Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yTdr2v8smxMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=200)\n",
        "x_test = pad_sequences(x_test, maxlen=200)\n",
        "\n",
        "def build_model(use_gru=False):\n",
        " model = Sequential([\n",
        " Embedding(input_dim=10000, output_dim=128, input_length=200),\n",
        " GRU(128) if use_gru else LSTM(128),\n",
        " Dense(1, activation='sigmoid')\n",
        " ])\n",
        " model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        " return model\n",
        "\n",
        "lstm_model = build_model(use_gru=False)\n",
        "lstm_history = lstm_model.fit(x_train, y_train, epochs=1, batch_size=64, validation_split=0.2)\n",
        "\n",
        "lstm_loss, lstm_accuracy = lstm_model.evaluate(x_test, y_test)\n",
        "print(f\"LSTM Test Accuracy: {lstm_accuracy:.4f}\")\n",
        "\n",
        "gru_model = build_model(use_gru=True)\n",
        "gru_history = gru_model.fit(x_train, y_train, epochs=1, batch_size=64, validation_split=0.2)\n",
        "\n",
        "gru_loss, gru_accuracy = gru_model.evaluate(x_test, y_test)\n",
        "print(f\"GRU Test Accuracy: {gru_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "Z0mbSDMtm30Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}