{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlENb3qjwQu8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed\n",
        "\n",
        "df = pd.read_csv('AA.csv')\n",
        "df = df[['Date', 'Close']]\n",
        "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "df = df.dropna(subset=['Date'])\n",
        "\n",
        "print(df['Date'].min(), df['Date'].max())\n",
        "cutoff_date = '2015-01-01'\n",
        "\n",
        "train = df.loc[df['Date'] < cutoff_date]\n",
        "test = df.loc[df['Date'] >= cutoff_date]\n",
        "\n",
        "train.shape, test.shape\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(train[['Close']])\n",
        "\n",
        "train['Close'] = scaler.transform(train[['Close']])\n",
        "test['Close'] = scaler.transform(test[['Close']])\n",
        "TIME_STEPS=30\n",
        "\n",
        "def create_sequences(X, y, time_steps=TIME_STEPS):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X)-time_steps):\n",
        "        Xs.append(X.iloc[i:(i+time_steps)].values)\n",
        "        ys.append(y.iloc[i+time_steps])\n",
        "\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "X_train, y_train = create_sequences(train[['Close']], train['Close'])\n",
        "X_test, y_test = create_sequences(test[['Close']], test['Close'])\n",
        "\n",
        "print(f'Training shape: {X_train.shape}')\n",
        "print(f'Testing shape: {X_test.shape}')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(RepeatVector(X_train.shape[1]))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(TimeDistributed(Dense(X_train.shape[2])))\n",
        "model.compile(optimizer='adam', loss='mae')\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='min')], shuffle=False)\n",
        "\n",
        "model.evaluate(X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_pred_inverse = scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
        "y_test_inverse = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(y_test_inverse, label='Original Close Prices', color='blue')\n",
        "plt.plot(y_pred_inverse, label='Reconstructed Close Prices', color='orange')\n",
        "plt.title('Original vs Reconstructed Close Prices')\n",
        "plt.xlabel('Time Steps')\n",
        "plt.ylabel('Close Price')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sL7zY1fx9FAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_pred = model.predict(X_test)\n",
        "\n",
        "reconstruction_error = np.mean(np.abs(X_test_pred - X_test), axis=1)\n",
        "\n",
        "threshold = np.percentile(reconstruction_error, 95)\n",
        "\n",
        "anomalies = reconstruction_error > threshold\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(reconstruction_error, label='Reconstruction Error')\n",
        "plt.axhline(y=threshold, color='r', linestyle='--', label='Threshold')\n",
        "plt.scatter(np.where(anomalies)[0], reconstruction_error[anomalies], color='red', label='Anomalies')\n",
        "plt.title('Reconstruction Error on Test Data')\n",
        "plt.xlabel('Time Step')\n",
        "plt.ylabel('Reconstruction Error')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ox1znXZ80Xsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_last = y_pred[:, -1, :]\n",
        "y_pred_inverse = scaler.inverse_transform(y_pred_last.reshape(-1, 1))\n",
        "y_test_inverse = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "reconstruction_errors = np.abs(y_test_inverse - y_pred_inverse)\n",
        "\n",
        "threshold = np.percentile(reconstruction_errors, 95)\n",
        "\n",
        "anomalies = reconstruction_errors.flatten() > threshold\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(y_test_inverse, label='Original Close Prices', color='blue')\n",
        "plt.plot(y_pred_inverse, label='Reconstructed Close Prices', color='orange')\n",
        "plt.scatter(np.where(anomalies)[0], y_test_inverse[anomalies], color='red', label='Anomalies', marker='o')\n",
        "plt.axhline(y=threshold, color='r', linestyle='--', label='Anomaly Threshold')\n",
        "plt.title('Anomaly Detection in Stock Prices')\n",
        "plt.xlabel('Time Steps')\n",
        "plt.ylabel('Close Price')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "anomaly_indices = np.where(anomalies)[0]\n",
        "print(\"Indices of detected anomalies:\", anomaly_indices)\n",
        "print(\"Anomalies (Close Prices):\", y_test_inverse[anomalies])\n"
      ],
      "metadata": {
        "id": "wyUGgDxd-Cyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(df) * 0.8)\n",
        "val_size = int(len(df) * 0.1)\n",
        "\n",
        "train_data = df.iloc[:train_size]\n",
        "val_data = df.iloc[train_size:train_size + val_size]\n",
        "test_data = df.iloc[train_size + val_size:]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(train_data[['Close']])\n",
        "\n",
        "train_data['Close'] = scaler.transform(train_data[['Close']])\n",
        "val_data['Close'] = scaler.transform(val_data[['Close']])\n",
        "test_data['Close'] = scaler.transform(test_data[['Close']])\n",
        "\n",
        "X_val, y_val = create_sequences(val_data[['Close']], val_data['Close'])\n",
        "\n",
        "y_val_pred = model.predict(X_val)\n",
        "\n",
        "y_val_pred_last = y_val_pred[:, -1, :]\n",
        "y_val_pred_inverse = scaler.inverse_transform(y_val_pred_last.reshape(-1, 1))\n",
        "y_val_inverse = scaler.inverse_transform(y_val.reshape(-1, 1))\n",
        "\n",
        "reconstruction_errors_val = np.abs(y_val_inverse - y_val_pred_inverse)\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(reconstruction_errors_val, label='Reconstruction Errors', color='purple')\n",
        "plt.title('Reconstruction Errors on Validation Dataset')\n",
        "plt.xlabel('Time Steps')\n",
        "plt.ylabel('Reconstruction Error')\n",
        "plt.axhline(y=np.percentile(reconstruction_errors_val, 95), color='red', linestyle='--', label='95th Percentile Threshold')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qqMPebfA-11U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, RepeatVector, TimeDistributed, Dense, Input\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_data(num_sequences, sequence_length, feature_dim):\n",
        "    return np.random.rand(num_sequences, sequence_length, feature_dim)\n",
        "\n",
        "num_sequences = 1000\n",
        "sequence_lengths = [10, 20, 30, 40, 50]\n",
        "feature_dim = 5\n",
        "latent_dim = 16\n",
        "batch_size = 32\n",
        "epochs = 1\n",
        "\n",
        "def create_lstm_autoencoder(sequence_length, feature_dim, latent_dim):\n",
        "    inputs = Input(shape=(sequence_length, feature_dim))\n",
        "    encoded = LSTM(latent_dim, activation=\"relu\")(inputs)\n",
        "    decoded = RepeatVector(sequence_length)(encoded)\n",
        "    decoded = LSTM(feature_dim, return_sequences=True)(decoded)\n",
        "    return Model(inputs, decoded)\n",
        "\n",
        "mse_scores = []\n",
        "for seq_len in sequence_lengths:\n",
        "    data = generate_data(num_sequences, seq_len, feature_dim)\n",
        "    model = create_lstm_autoencoder(seq_len, feature_dim, latent_dim)\n",
        "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "    model.fit(data, data, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "    reconstructed_data = model.predict(data)\n",
        "    mse = mean_squared_error(data.reshape(-1, feature_dim), reconstructed_data.reshape(-1, feature_dim))\n",
        "    mse_scores.append(mse)\n",
        "\n",
        "plt.plot(sequence_lengths, mse_scores, marker='o')\n",
        "plt.xlabel(\"Sequence Length\")\n",
        "plt.ylabel(\"Mean Squared Error (Reconstruction)\")\n",
        "plt.title(\"Reconstruction Error vs Sequence Length\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "74FJh35x1xKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "time_steps = 1000\n",
        "anomaly_fraction = 0.1\n",
        "\n",
        "t = np.arange(0, time_steps)\n",
        "normal_data = np.sin(0.02 * t)\n",
        "\n",
        "normal_data += 0.05 * np.random.normal(size=time_steps)\n",
        "\n",
        "num_anomalies = int(anomaly_fraction * time_steps)\n",
        "anomaly_indices = np.random.choice(time_steps, num_anomalies, replace=False)\n",
        "anomalous_data = normal_data.copy()\n",
        "anomalous_data[anomaly_indices] += np.random.uniform(3, 5, size=num_anomalies)\n",
        "\n",
        "labels = np.zeros(time_steps)\n",
        "labels[anomaly_indices] = 1\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, RepeatVector, TimeDistributed, Dense\n",
        "\n",
        "def create_lstm_autoencoder(sequence_length, n_features):\n",
        "    model = Sequential([\n",
        "        LSTM(64, activation=\"relu\", input_shape=(sequence_length, n_features), return_sequences=True),\n",
        "        LSTM(32, activation=\"relu\", return_sequences=False),\n",
        "        RepeatVector(sequence_length),\n",
        "        LSTM(32, activation=\"relu\", return_sequences=True),\n",
        "        LSTM(64, activation=\"relu\", return_sequences=True),\n",
        "        TimeDistributed(Dense(n_features))\n",
        "    ])\n",
        "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "sequence_length = 50\n",
        "n_features = 1\n",
        "\n",
        "def create_sequences(data, seq_length):\n",
        "    sequences = []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        sequence = data[i:i + seq_length]\n",
        "        sequences.append(sequence)\n",
        "    return np.array(sequences)\n",
        "\n",
        "normal_sequences = create_sequences(normal_data.reshape(-1, 1), sequence_length)\n",
        "anomalous_sequences = create_sequences(anomalous_data.reshape(-1, 1), sequence_length)\n",
        "labels_sequences = create_sequences(labels, sequence_length)\n",
        "model = create_lstm_autoencoder(sequence_length, n_features)\n",
        "history = model.fit(normal_sequences, normal_sequences, epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n",
        "\n",
        "plt.plot(history.history['loss'], label=\"Training Loss\")\n",
        "plt.plot(history.history['val_loss'], label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "reconstructed_sequences = model.predict(anomalous_sequences)\n",
        "mse = np.mean(np.power(anomalous_sequences - reconstructed_sequences, 2), axis=(1, 2))\n",
        "\n",
        "threshold = np.percentile(mse[:len(normal_sequences)], 95)\n",
        "\n",
        "predicted_anomalies = mse > threshold"
      ],
      "metadata": {
        "id": "rsS1IUOn11dS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nm3I3qsh7DQP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}